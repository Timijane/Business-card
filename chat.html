<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
<title>MEET | Professional Chat with Calls</title>
<link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500;600;700&display=swap" rel="stylesheet">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
<style>
  /* Existing styles remain the same... */
  /* I'll only add new styles for WebRTC features to avoid duplication */
  
  /* WebRTC Call Styles */
  .call-modal {
    display: none;
    position: fixed;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    background: rgba(0, 0, 0, 0.9);
    z-index: 3000;
    align-items: center;
    justify-content: center;
    animation: modalFadeIn 0.3s forwards;
  }
  
  .call-container {
    background: var(--card-bg);
    border-radius: 20px;
    overflow: hidden;
    width: 95%;
    max-width: 900px;
    height: 85vh;
    display: flex;
    flex-direction: column;
    box-shadow: 0 20px 60px rgba(0, 0, 0, 0.5);
  }
  
  .call-header {
    background: linear-gradient(135deg, #0080FF 0%, #0066CC 100%);
    padding: 20px;
    color: white;
    display: flex;
    justify-content: space-between;
    align-items: center;
  }
  
  .call-title {
    font-size: 20px;
    font-weight: 600;
  }
  
  .call-duration {
    font-size: 14px;
    opacity: 0.9;
  }
  
  .call-video-container {
    flex: 1;
    display: flex;
    position: relative;
    overflow: hidden;
  }
  
  .main-video {
    flex: 1;
    background: #000;
    position: relative;
  }
  
  .secondary-video {
    position: absolute;
    bottom: 20px;
    right: 20px;
    width: 200px;
    height: 150px;
    border-radius: 10px;
    overflow: hidden;
    box-shadow: 0 4px 20px rgba(0, 0, 0, 0.3);
    border: 2px solid var(--primary);
  }
  
  .video-element {
    width: 100%;
    height: 100%;
    object-fit: cover;
  }
  
  .call-chat-sidebar {
    width: 300px;
    background: var(--card-bg);
    border-left: 1px solid var(--border-color);
    display: flex;
    flex-direction: column;
  }
  
  .call-chat-header {
    padding: 15px;
    border-bottom: 1px solid var(--border-color);
    font-weight: 600;
    color: var(--text-color);
  }
  
  .call-messages {
    flex: 1;
    overflow-y: auto;
    padding: 15px;
    display: flex;
    flex-direction: column;
    gap: 10px;
  }
  
  .call-message {
    background: var(--bg-color);
    padding: 10px 15px;
    border-radius: 10px;
    max-width: 100%;
  }
  
  .call-message.sent {
    background: var(--primary);
    color: white;
    align-self: flex-end;
  }
  
  .call-message-input-container {
    padding: 15px;
    border-top: 1px solid var(--border-color);
    display: flex;
    gap: 10px;
  }
  
  .call-message-input {
    flex: 1;
    padding: 12px 15px;
    border-radius: 25px;
    border: 1px solid var(--border-color);
    background: var(--bg-color);
    color: var(--text-color);
    outline: none;
  }
  
  .call-controls {
    padding: 20px;
    background: var(--card-bg);
    display: flex;
    justify-content: center;
    gap: 20px;
    border-top: 1px solid var(--border-color);
  }
  
  .call-btn {
    width: 60px;
    height: 60px;
    border-radius: 50%;
    border: none;
    cursor: pointer;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 20px;
    transition: all 0.3s ease;
  }
  
  .call-btn.accept {
    background: linear-gradient(135deg, #10B981 0%, #059669 100%);
    color: white;
  }
  
  .call-btn.reject {
    background: linear-gradient(135deg, #EF4444 0%, #DC2626 100%);
    color: white;
  }
  
  .call-btn.toggle {
    background: var(--bg-color);
    color: var(--text-color);
  }
  
  .call-btn.active {
    background: var(--primary);
    color: white;
  }
  
  .call-btn:hover {
    transform: scale(1.1);
    box-shadow: 0 6px 20px rgba(0, 0, 0, 0.2);
  }
  
  .incoming-call-modal {
    display: none;
    position: fixed;
    top: 50%;
    left: 50%;
    transform: translate(-50%, -50%);
    background: var(--card-bg);
    border-radius: 20px;
    padding: 30px;
    z-index: 4000;
    text-align: center;
    box-shadow: 0 20px 60px rgba(0, 0, 0, 0.4);
    min-width: 300px;
  }
  
  .caller-info {
    display: flex;
    flex-direction: column;
    align-items: center;
    gap: 15px;
    margin-bottom: 30px;
  }
  
  .caller-avatar {
    width: 80px;
    height: 80px;
    border-radius: 50%;
    object-fit: cover;
    border: 3px solid var(--primary);
  }
  
  .caller-name {
    font-size: 24px;
    font-weight: 600;
    color: var(--text-color);
  }
  
  .call-type {
    color: var(--secondary-text);
    font-size: 16px;
  }
  
  .incoming-call-controls {
    display: flex;
    gap: 20px;
    justify-content: center;
  }
  
  /* Voice Message Styles */
  .voice-message-container {
    display: flex;
    align-items: center;
    gap: 10px;
    padding: 10px 15px;
    background: var(--bg-color);
    border-radius: 25px;
    margin: 5px 0;
  }
  
  .voice-play-btn {
    width: 40px;
    height: 40px;
    border-radius: 50%;
    background: var(--primary);
    color: white;
    border: none;
    cursor: pointer;
    display: flex;
    align-items: center;
    justify-content: center;
  }
  
  .voice-waveform {
    flex: 1;
    height: 40px;
    background: linear-gradient(90deg, var(--primary) 50%, transparent 50%);
    border-radius: 5px;
    position: relative;
    overflow: hidden;
  }
  
  .voice-wave {
    position: absolute;
    height: 100%;
    width: 100%;
    background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.3), transparent);
    animation: wave 1s infinite linear;
  }
  
  @keyframes wave {
    0% { transform: translateX(-100%); }
    100% { transform: translateX(100%); }
  }
  
  .voice-duration {
    font-size: 12px;
    color: var(--secondary-text);
    min-width: 40px;
    text-align: center;
  }
  
  /* Recording Styles */
  .recording-overlay {
    position: fixed;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    background: rgba(0, 0, 0, 0.7);
    z-index: 5000;
    display: none;
    align-items: center;
    justify-content: center;
  }
  
  .recording-container {
    background: var(--card-bg);
    border-radius: 20px;
    padding: 40px;
    text-align: center;
    min-width: 300px;
  }
  
  .recording-indicator {
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 10px;
    margin-bottom: 20px;
  }
  
  .recording-dot {
    width: 10px;
    height: 10px;
    border-radius: 50%;
    background: #EF4444;
    animation: pulse 1.5s infinite;
  }
  
  @keyframes pulse {
    0%, 100% { opacity: 1; }
    50% { opacity: 0.5; }
  }
  
  .recording-time {
    font-size: 24px;
    font-weight: 600;
    color: var(--text-color);
  }
  
  .recording-controls {
    display: flex;
    gap: 20px;
    justify-content: center;
    margin-top: 30px;
  }
  
  /* Notification Bell */
  .notification-bell {
    position: relative;
    cursor: pointer;
  }
  
  .bell-notification {
    position: absolute;
    top: -5px;
    right: -5px;
    width: 8px;
    height: 8px;
    border-radius: 50%;
    background: #EF4444;
    animation: bellRing 2s infinite;
  }
  
  @keyframes bellRing {
    0%, 100% { transform: scale(1); }
    50% { transform: scale(1.2); }
  }
  
  /* Responsive adjustments */
  @media (max-width: 768px) {
    .call-container {
      flex-direction: column;
      height: 100vh;
      border-radius: 0;
      max-width: 100%;
    }
    
    .call-chat-sidebar {
      width: 100%;
      height: 40vh;
      border-left: none;
      border-top: 1px solid var(--border-color);
    }
    
    .secondary-video {
      width: 120px;
      height: 90px;
    }
    
    .call-btn {
      width: 50px;
      height: 50px;
    }
    
    .incoming-call-modal {
      width: 90%;
    }
  }
</style>
</head>
<body>
<!-- All existing HTML remains the same until after the existing modals -->

<!-- Voice Message Recording Overlay -->
<div class="recording-overlay" id="recordingOverlay">
  <div class="recording-container">
    <div class="recording-indicator">
      <div class="recording-dot"></div>
      <span style="color: #EF4444; font-weight: 600;">Recording</span>
    </div>
    <div class="recording-time" id="recordingTime">00:00</div>
    <div class="recording-controls">
      <button class="call-btn reject" onclick="stopRecording()">
        <i class="fas fa-stop"></i>
      </button>
      <button class="call-btn accept" onclick="sendVoiceMessage()">
        <i class="fas fa-check"></i>
      </button>
    </div>
  </div>
</div>

<!-- Incoming Call Modal -->
<div class="incoming-call-modal" id="incomingCallModal">
  <div class="caller-info">
    <img id="incomingCallerAvatar" src="" class="caller-avatar" alt="Caller">
    <div class="caller-name" id="incomingCallerName">User</div>
    <div class="call-type" id="incomingCallType">Incoming Video Call</div>
  </div>
  <div class="incoming-call-controls">
    <button class="call-btn accept" onclick="acceptCall()">
      <i class="fas fa-phone-alt"></i>
    </button>
    <button class="call-btn reject" onclick="rejectCall()">
      <i class="fas fa-times"></i>
    </button>
  </div>
</div>

<!-- Active Call Modal -->
<div class="call-modal" id="callModal">
  <div class="call-container">
    <div class="call-header">
      <div class="call-title">
        <span id="callTitle">Call with User</span>
        <span class="call-duration" id="callDuration">00:00</span>
      </div>
      <button onclick="endCall()" style="background:none;border:none;color:white;font-size:24px;cursor:pointer;">
        <i class="fas fa-times"></i>
      </button>
    </div>
    
    <div class="call-video-container">
      <div class="main-video" id="mainVideo">
        <video id="remoteVideo" class="video-element" autoplay playsinline></video>
      </div>
      <div class="secondary-video" id="secondaryVideo">
        <video id="localVideo" class="video-element" autoplay playsinline muted></video>
      </div>
    </div>
    
    <div class="call-chat-sidebar" id="callChatSidebar">
      <div class="call-chat-header">
        <i class="fas fa-comments"></i> Call Chat
      </div>
      <div class="call-messages" id="callMessages"></div>
      <div class="call-message-input-container">
        <input type="text" class="call-message-input" id="callMessageInput" placeholder="Type message...">
        <button class="call-btn toggle" onclick="sendCallMessage()">
          <i class="fas fa-paper-plane"></i>
        </button>
      </div>
    </div>
    
    <div class="call-controls">
      <button class="call-btn toggle" id="toggleMic" onclick="toggleMic()">
        <i class="fas fa-microphone"></i>
      </button>
      <button class="call-btn toggle" id="toggleCamera" onclick="toggleCamera()">
        <i class="fas fa-video"></i>
      </button>
      <button class="call-btn toggle" onclick="toggleChat()">
        <i class="fas fa-comments"></i>
      </button>
      <button class="call-btn toggle" onclick="ringBell()">
        <i class="fas fa-bell"></i>
      </button>
      <button class="call-btn reject" onclick="endCall()">
        <i class="fas fa-phone-slash"></i>
      </button>
    </div>
  </div>
</div>

<!-- Add voice message button to existing message input -->
<script type="module">
  import { initializeApp } from "https://www.gstatic.com/firebasejs/10.14.0/firebase-app.js";
  import { getFirestore, collection, addDoc, updateDoc, doc, getDoc, getDocs, onSnapshot, serverTimestamp, query, orderBy, where, setDoc, limit, deleteDoc } from "https://www.gstatic.com/firebasejs/10.14.0/firebase-firestore.js";
  import { getAuth, onAuthStateChanged, signOut } from "https://www.gstatic.com/firebasejs/10.14.0/firebase-auth.js";

  const firebaseConfig = {
    apiKey: "AIzaSyDtqM_pMGIYkUgy0OWGsQbfS9MtYQhrgZM",
    authDomain: "meet-6e159.firebaseapp.com",
    projectId: "meet-6e159",
    storageBucket: "meet-6e159.firebasestorage.app",
    messagingSenderId: "252353608421",
    appId: "1:252353608421:web:6706056048e9a8f12db20c"
  };

  const app = initializeApp(firebaseConfig);
  const db = getFirestore(app);
  const auth = getAuth(app);

  // WebRTC Configuration
  const configuration = {
    iceServers: [
      { urls: 'stun:stun.l.google.com:19302' },
      { urls: 'stun:stun1.l.google.com:19302' },
      { urls: 'stun:stun2.l.google.com:19302' },
      { urls: 'stun:stun3.l.google.com:19302' },
      { urls: 'stun:stun4.l.google.com:19302' }
    ]
  };

  // Global variables for WebRTC
  let peerConnection = null;
  let localStream = null;
  let remoteStream = null;
  let callType = null; // 'video' or 'audio'
  let currentCall = null;
  let callStartTime = null;
  let callTimer = null;
  let isMicMuted = false;
  let isCameraOff = false;
  let isChatVisible = true;
  
  // Voice recording variables
  let mediaRecorder = null;
  let recordedChunks = [];
  let recordingTimer = null;
  let recordingStartTime = null;
  
  // Add voice message button to message input actions
  function addVoiceMessageButton() {
    const messageInputActions = document.querySelector('.message-input-actions');
    if (!messageInputActions) return;
    
    const voiceBtn = document.createElement('button');
    voiceBtn.className = 'input-action';
    voiceBtn.title = 'Voice Message';
    voiceBtn.innerHTML = '<i class="fas fa-microphone"></i>';
    voiceBtn.onclick = startVoiceRecording;
    
    // Insert after the existing buttons
    messageInputActions.insertBefore(voiceBtn, messageInputActions.children[2]);
  }

  // Voice Recording Functions
  async function startVoiceRecording() {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRecorder = new MediaRecorder(stream);
      recordedChunks = [];
      
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          recordedChunks.push(event.data);
        }
      };
      
      mediaRecorder.start();
      recordingStartTime = Date.now();
      updateRecordingTime();
      recordingTimer = setInterval(updateRecordingTime, 1000);
      
      document.getElementById('recordingOverlay').style.display = 'flex';
      
    } catch (error) {
      console.error('Error accessing microphone:', error);
      alert('Could not access microphone. Please check permissions.');
    }
  }
  
  function updateRecordingTime() {
    const elapsed = Math.floor((Date.now() - recordingStartTime) / 1000);
    const minutes = Math.floor(elapsed / 60).toString().padStart(2, '0');
    const seconds = (elapsed % 60).toString().padStart(2, '0');
    document.getElementById('recordingTime').textContent = `${minutes}:${seconds}`;
  }
  
  function stopRecording() {
    if (mediaRecorder && mediaRecorder.state !== 'inactive') {
      mediaRecorder.stop();
    }
    cleanupRecording();
  }
  
  async function sendVoiceMessage() {
    if (recordedChunks.length === 0) {
      cleanupRecording();
      return;
    }
    
    const blob = new Blob(recordedChunks, { type: 'audio/webm' });
    
    // Stop all tracks
    if (mediaRecorder.stream) {
      mediaRecorder.stream.getTracks().forEach(track => track.stop());
    }
    
    // Upload to Cloudinary
    const formData = new FormData();
    formData.append('file', blob, 'voice-message.webm');
    formData.append('upload_preset', 'Meet_video');
    formData.append('resource_type', 'auto');
    
    try {
      const response = await fetch(`https://api.cloudinary.com/v1_1/dcwof2ngn/upload`, {
        method: 'POST',
        body: formData
      });
      
      if (!response.ok) throw new Error('Upload failed');
      
      const data = await response.json();
      
      // Send voice message to current chat
      if (currentChatId) {
        await addDoc(collection(db, "conversations", currentChatId, "messages"), {
          mediaUrl: data.secure_url,
          mediaType: 'audio',
          text: '',
          senderId: currentUser.uid,
          timestamp: serverTimestamp(),
          duration: Math.floor((Date.now() - recordingStartTime) / 1000)
        });
      }
      
    } catch (error) {
      console.error('Voice message upload error:', error);
      alert('Failed to send voice message');
    } finally {
      cleanupRecording();
    }
  }
  
  function cleanupRecording() {
    clearInterval(recordingTimer);
    document.getElementById('recordingOverlay').style.display = 'none';
    recordedChunks = [];
    
    if (mediaRecorder && mediaRecorder.stream) {
      mediaRecorder.stream.getTracks().forEach(track => track.stop());
    }
  }

  // WebRTC Call Functions
  async function startVideoCall() {
    if (!currentChatUser) {
      alert('Please select a conversation first');
      return;
    }
    
    callType = 'video';
    await initLocalStream(true, true);
    setupCallModal();
    document.getElementById('callModal').style.display = 'flex';
    startCall();
  }
  
  async function startVoiceCall() {
    if (!currentChatUser) {
      alert('Please select a conversation first');
      return;
    }
    
    callType = 'audio';
    await initLocalStream(true, false);
    setupCallModal();
    document.getElementById('callModal').style.display = 'flex';
    startCall();
  }
  
  async function initLocalStream(audio = true, video = true) {
    try {
      const constraints = {
        audio: audio,
        video: video ? {
          width: { ideal: 1280 },
          height: { ideal: 720 },
          facingMode: 'user'
        } : false
      };
      
      localStream = await navigator.mediaDevices.getUserMedia(constraints);
      
      // Display local video if it's a video call
      if (video && callType === 'video') {
        const localVideo = document.getElementById('localVideo');
        localVideo.srcObject = localStream;
      }
      
    } catch (error) {
      console.error('Error accessing media devices:', error);
      alert('Could not access camera/microphone. Please check permissions.');
      throw error;
    }
  }
  
  function setupCallModal() {
    document.getElementById('callTitle').textContent = `Call with ${currentChatUserName}`;
    document.getElementById('callDuration').textContent = '00:00';
    
    // Hide/show video elements based on call type
    if (callType === 'audio') {
      document.getElementById('secondaryVideo').style.display = 'none';
      document.getElementById('mainVideo').innerHTML = `
        <div style="display:flex; flex-direction:column; align-items:center; justify-content:center; height:100%; color:white; gap:20px;">
          <img src="${currentChatUserAvatar}" style="width:120px; height:120px; border-radius:50%; object-fit:cover;">
          <div style="font-size:24px; font-weight:600;">${currentChatUserName}</div>
          <div style="font-size:16px; opacity:0.8;">Voice Call</div>
        </div>
      `;
    } else {
      document.getElementById('secondaryVideo').style.display = 'block';
    }
  }
  
  async function startCall() {
    try {
      // Create peer connection
      peerConnection = new RTCPeerConnection(configuration);
      
      // Add local stream tracks
      localStream.getTracks().forEach(track => {
        peerConnection.addTrack(track, localStream);
      });
      
      // Handle remote stream
      peerConnection.ontrack = (event) => {
        remoteStream = event.streams[0];
        const remoteVideo = document.getElementById('remoteVideo');
        remoteVideo.srcObject = remoteStream;
      };
      
      // Handle ICE candidates
      peerConnection.onicecandidate = (event) => {
        if (event.candidate && currentCall) {
          // Send ICE candidate to the other peer
          updateDoc(doc(db, "calls", currentCall.id), {
            candidate: event.candidate.toJSON(),
            timestamp: serverTimestamp()
          });
        }
      };
      
      // Create offer
      const offer = await peerConnection.createOffer();
      await peerConnection.setLocalDescription(offer);
      
      // Create call document in Firestore
      const callDoc = await addDoc(collection(db, "calls"), {
        callerId: currentUser.uid,
        calleeId: currentChatUser,
        offer: offer,
        type: callType,
        status: 'ringing',
        createdAt: serverTimestamp()
      });
      
      currentCall = { id: callDoc.id, ...offer };
      
      // Start call timer
      callStartTime = Date.now();
      startCallTimer();
      
      // Listen for answer
      const unsubscribe = onSnapshot(doc(db, "calls", callDoc.id), async (snapshot) => {
        const callData = snapshot.data();
        
        if (callData.answer && peerConnection.signalingState === 'have-local-offer') {
          const answer = new RTCSessionDescription(callData.answer);
          await peerConnection.setRemoteDescription(answer);
        }
        
        if (callData.candidate) {
          await peerConnection.addIceCandidate(new RTCIceCandidate(callData.candidate));
        }
        
        if (callData.status === 'ended') {
          endCall();
        }
      });
      
    } catch (error) {
      console.error('Error starting call:', error);
      alert('Failed to start call. Please try again.');
      endCall();
    }
  }
  
  function startCallTimer() {
    clearInterval(callTimer);
    callTimer = setInterval(() => {
      if (callStartTime) {
        const elapsed = Math.floor((Date.now() - callStartTime) / 1000);
        const minutes = Math.floor(elapsed / 60).toString().padStart(2, '0');
        const seconds = (elapsed % 60).toString().padStart(2, '0');
        document.getElementById('callDuration').textContent = `${minutes}:${seconds}`;
      }
    }, 1000);
  }
  
  async function acceptCall() {
    try {
      await initLocalStream(true, callType === 'video');
      
      // Create peer connection
      peerConnection = new RTCPeerConnection(configuration);
      
      // Add local stream tracks
      localStream.getTracks().forEach(track => {
        peerConnection.addTrack(track, localStream);
      });
      
      // Handle remote stream
      peerConnection.ontrack = (event) => {
        remoteStream = event.streams[0];
        const remoteVideo = document.getElementById('remoteVideo');
        remoteVideo.srcObject = remoteStream;
      };
      
      // Handle ICE candidates
      peerConnection.onicecandidate = (event) => {
        if (event.candidate && currentCall) {
          updateDoc(doc(db, "calls", currentCall.id), {
            candidate: event.candidate.toJSON(),
            timestamp: serverTimestamp()
          });
        }
      };
      
      // Set remote description from offer
      const offer = new RTCSessionDescription(currentCall.offer);
      await peerConnection.setRemoteDescription(offer);
      
      // Create and set local description
      const answer = await peerConnection.createAnswer();
      await peerConnection.setLocalDescription(answer);
      
      // Send answer to caller
      await updateDoc(doc(db, "calls", currentCall.id), {
        answer: answer,
        status: 'active',
        timestamp: serverTimestamp()
      });
      
      // Setup call modal
      setupCallModal();
      document.getElementById('incomingCallModal').style.display = 'none';
      document.getElementById('callModal').style.display = 'flex';
      
      // Start call timer
      callStartTime = Date.now();
      startCallTimer();
      
    } catch (error) {
      console.error('Error accepting call:', error);
      alert('Failed to accept call');
      endCall();
    }
  }
  
  function rejectCall() {
    if (currentCall) {
      updateDoc(doc(db, "calls", currentCall.id), {
        status: 'rejected',
        timestamp: serverTimestamp()
      });
    }
    cleanupCall();
    document.getElementById('incomingCallModal').style.display = 'none';
  }
  
  async function endCall() {
    if (currentCall) {
      await updateDoc(doc(db, "calls", currentCall.id), {
        status: 'ended',
        endedAt: serverTimestamp()
      });
    }
    cleanupCall();
    document.getElementById('callModal').style.display = 'none';
    document.getElementById('incomingCallModal').style.display = 'none';
  }
  
  function cleanupCall() {
    // Stop all media tracks
    if (localStream) {
      localStream.getTracks().forEach(track => track.stop());
      localStream = null;
    }
    
    if (remoteStream) {
      remoteStream.getTracks().forEach(track => track.stop());
      remoteStream = null;
    }
    
    // Close peer connection
    if (peerConnection) {
      peerConnection.close();
      peerConnection = null;
    }
    
    // Clear timers
    clearInterval(callTimer);
    callStartTime = null;
    currentCall = null;
    callType = null;
  }
  
  // Call Control Functions
  function toggleMic() {
    if (!localStream) return;
    
    const audioTrack = localStream.getAudioTracks()[0];
    if (audioTrack) {
      audioTrack.enabled = !audioTrack.enabled;
      isMicMuted = !audioTrack.enabled;
      
      const micBtn = document.getElementById('toggleMic');
      micBtn.classList.toggle('active', isMicMuted);
      micBtn.innerHTML = isMicMuted ? '<i class="fas fa-microphone-slash"></i>' : '<i class="fas fa-microphone"></i>';
    }
  }
  
  function toggleCamera() {
    if (!localStream || callType !== 'video') return;
    
    const videoTrack = localStream.getVideoTracks()[0];
    if (videoTrack) {
      videoTrack.enabled = !videoTrack.enabled;
      isCameraOff = !videoTrack.enabled;
      
      const cameraBtn = document.getElementById('toggleCamera');
      cameraBtn.classList.toggle('active', isCameraOff);
      cameraBtn.innerHTML = isCameraOff ? '<i class="fas fa-video-slash"></i>' : '<i class="fas fa-video"></i>';
      
      // Show/hide local video
      const localVideo = document.getElementById('localVideo');
      localVideo.style.opacity = isCameraOff ? '0.5' : '1';
    }
  }
  
  function toggleChat() {
    isChatVisible = !isChatVisible;
    const chatSidebar = document.getElementById('callChatSidebar');
    chatSidebar.style.display = isChatVisible ? 'flex' : 'none';
  }
  
  function ringBell() {
    // Create bell ring effect
    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
    const oscillator = audioContext.createOscillator();
    const gainNode = audioContext.createGain();
    
    oscillator.connect(gainNode);
    gainNode.connect(audioContext.destination);
    
    oscillator.frequency.setValueAtTime(800, audioContext.currentTime);
    oscillator.frequency.setValueAtTime(1000, audioContext.currentTime + 0.1);
    oscillator.frequency.setValueAtTime(800, audioContext.currentTime + 0.2);
    
    gainNode.gain.setValueAtTime(0.3, audioContext.currentTime);
    gainNode.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + 0.3);
    
    oscillator.start(audioContext.currentTime);
    oscillator.stop(audioContext.currentTime + 0.3);
    
    // Visual effect
    const callContainer = document.querySelector('.call-container');
    callContainer.style.boxShadow = '0 0 30px #FF9900';
    setTimeout(() => {
      callContainer.style.boxShadow = '0 20px 60px rgba(0, 0, 0, 0.5)';
    }, 300);
  }
  
  // Call Chat Functions
  async function sendCallMessage() {
    const input = document.getElementById('callMessageInput');
    const text = input.value.trim();
    
    if (!text || !currentCall) return;
    
    // Add message to call chat
    const messagesDiv = document.getElementById('callMessages');
    const messageDiv = document.createElement('div');
    messageDiv.className = 'call-message sent';
    messageDiv.textContent = text;
    messagesDiv.appendChild(messageDiv);
    messagesDiv.scrollTop = messagesDiv.scrollHeight;
    
    // Clear input
    input.value = '';
    
    // Send message through data channel (if available)
    // For now, we'll use Firestore for call messages
    if (currentCall && currentChatId) {
      await addDoc(collection(db, "conversations", currentChatId, "messages"), {
        text: `[During call]: ${text}`,
        senderId: currentUser.uid,
        timestamp: serverTimestamp(),
        isCallMessage: true
      });
    }
  }
  
  // Listen for incoming calls
  function listenForIncomingCalls() {
    if (!currentUser) return;
    
    const q = query(
      collection(db, "calls"),
      where("calleeId", "==", currentUser.uid),
      where("status", "==", "ringing"),
      orderBy("createdAt", "desc"),
      limit(1)
    );
    
    onSnapshot(q, async (snapshot) => {
      snapshot.docChanges().forEach(async (change) => {
        if (change.type === 'added') {
          const callData = change.doc.data();
          currentCall = { id: change.doc.id, offer: callData.offer };
          callType = callData.type;
          
          // Get caller info
          const callerDoc = await getDoc(doc(db, "users", callData.callerId));
          const callerData = callerDoc.exists() ? callerDoc.data() : {};
          const callerName = callerData.name || callerData.displayName || 'Unknown';
          const callerAvatar = callerData.photoURL || `https://ui-avatars.com/api/?name=${encodeURIComponent(callerName)}&background=0080FF&color=fff`;
          
          // Show incoming call modal
          document.getElementById('incomingCallerName').textContent = callerName;
          document.getElementById('incomingCallerAvatar').src = callerAvatar;
          document.getElementById('incomingCallType').textContent = 
            callType === 'video' ? 'Incoming Video Call' : 'Incoming Voice Call';
          
          document.getElementById('incomingCallModal').style.display = 'block';
        }
      });
    });
  }
  
  // Initialize voice messages and call listeners
  onAuthStateChanged(auth, async user => {
    if (!user) {
      window.location.href = 'login.html';
    } else {
      currentUser = user;
      
      // Add voice message button after user is authenticated
      setTimeout(addVoiceMessageButton, 1000);
      
      // Listen for incoming calls
      listenForIncomingCalls();
      
      // All existing auth code remains...
    }
  });

  // Render voice messages in chat
  function renderVoiceMessageHTML(msg, isMe) {
    const div = document.createElement('div');
    div.className = `message-wrapper ${isMe ? 'sent' : 'received'}`;
    
    div.innerHTML = `
      <div class="message-bubble">
        <div class="voice-message-container">
          <button class="voice-play-btn" onclick="playVoiceMessage('${msg.mediaUrl}', ${msg.duration || 0})">
            <i class="fas fa-play"></i>
          </button>
          <div class="voice-waveform">
            <div class="voice-wave"></div>
          </div>
          <div class="voice-duration">${formatDuration(msg.duration || 0)}</div>
        </div>
        <div class="message-time">
          ${msg.timestamp ? new Date(msg.timestamp.seconds * 1000).toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' }) : ''}
        </div>
      </div>
    `;
    
    return div;
  }

  function formatDuration(seconds) {
    const mins = Math.floor(seconds / 60);
    const secs = Math.floor(seconds % 60);
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
  }

  function playVoiceMessage(url, duration) {
    const audio = new Audio(url);
    audio.play();
    
    // You could add visual feedback here
    const btn = event.target.closest('.voice-play-btn');
    const originalHTML = btn.innerHTML;
    btn.innerHTML = '<i class="fas fa-pause"></i>';
    btn.disabled = true;
    
    setTimeout(() => {
      btn.innerHTML = originalHTML;
      btn.disabled = false;
    }, duration * 1000);
  }

  // Update renderMessageHTML to handle voice messages
  function renderMessageHTML(msg, isMe, id) {
    if (msg.mediaType === 'audio') {
      return renderVoiceMessageHTML(msg, isMe, id);
    }
    
    // Existing renderMessageHTML code remains...
  }

</script>
</body>
  </html>
