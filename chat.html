<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
<title>MEET | Professional Chat</title>
<link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500;600;700&display=swap" rel="stylesheet">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
<style>
  :root {
    --primary: #0080FF;
    --primary-dark: #0066CC;
    --bg-color: #f0f2f5;
    --card-bg: #fff;
    --text-color: #111;
    --secondary-text: #65676b;
    --border-color: #dddfe2;
    --error: #EF4444;
    --success: #10B981;
    --warning: #F59E0B;
    --app-height: 100dvh;
    --chat-font: 'Poppins', sans-serif;
    --sent-bubble-bg: #0080FF;
    --sent-text-color: #fff;
    --received-bubble-bg: #fff;
    --received-text-color: #111;
    --shadow-light: 0 2px 10px rgba(0,0,0,0.05);
    --shadow-medium: 0 4px 15px rgba(0,128,255,0.2);
    --shadow-heavy: 0 10px 40px rgba(0,0,0,0.2);
  }

  /* [Previous CSS styles remain the same until we add new ones] */

  /* === WEBRTC CALL INTERFACE STYLES === */
  .call-interface {
    position: fixed;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    background: #000;
    z-index: 3000;
    display: none;
    flex-direction: column;
  }

  .call-active .call-interface {
    display: flex;
  }

  .video-container {
    flex: 1;
    display: flex;
    position: relative;
    overflow: hidden;
  }

  .local-video-container {
    position: absolute;
    top: 20px;
    right: 20px;
    width: 120px;
    height: 160px;
    border-radius: 12px;
    overflow: hidden;
    box-shadow: 0 4px 20px rgba(0,0,0,0.5);
    z-index: 10;
    border: 2px solid var(--primary);
  }

  .remote-video-container {
    flex: 1;
    display: flex;
    align-items: center;
    justify-content: center;
    background: #000;
    position: relative;
  }

  .video-element {
    width: 100%;
    height: 100%;
    object-fit: cover;
  }

  .local-video {
    width: 100%;
    height: 100%;
    object-fit: cover;
    transform: scaleX(-1); /* Mirror local video */
  }

  .remote-video-wrapper {
    position: relative;
    width: 90%;
    height: 90%;
    max-width: 1200px;
    border-radius: 16px;
    overflow: hidden;
    box-shadow: 0 10px 40px rgba(0,128,255,0.3);
  }

  .call-controls {
    position: absolute;
    bottom: 30px;
    left: 0;
    right: 0;
    display: flex;
    justify-content: center;
    gap: 20px;
    padding: 20px;
    z-index: 20;
  }

  .call-btn {
    width: 60px;
    height: 60px;
    border-radius: 50%;
    border: none;
    cursor: pointer;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 20px;
    transition: all 0.2s ease;
    box-shadow: 0 4px 15px rgba(0,0,0,0.3);
  }

  .call-btn:hover {
    transform: scale(1.1);
    box-shadow: 0 6px 20px rgba(0,0,0,0.4);
  }

  .end-call-btn {
    background: var(--error);
    color: white;
  }

  .mute-btn {
    background: rgba(255,255,255,0.2);
    backdrop-filter: blur(10px);
    color: white;
  }

  .mute-btn.active {
    background: var(--error);
  }

  .video-toggle-btn {
    background: rgba(255,255,255,0.2);
    backdrop-filter: blur(10px);
    color: white;
  }

  .video-toggle-btn.active {
    background: var(--error);
  }

  .call-info {
    position: absolute;
    top: 30px;
    left: 30px;
    color: white;
    z-index: 10;
    backdrop-filter: blur(10px);
    padding: 15px 25px;
    border-radius: 12px;
    background: rgba(0,0,0,0.5);
  }

  .caller-name {
    font-size: 24px;
    font-weight: 600;
    margin-bottom: 5px;
  }

  .call-status {
    font-size: 14px;
    opacity: 0.8;
  }

  /* Shy chat overlay during call */
  .shy-chat-overlay {
    position: absolute;
    bottom: 100px;
    left: 50%;
    transform: translateX(-50%);
    background: rgba(0,0,0,0.7);
    color: white;
    padding: 12px 20px;
    border-radius: 12px;
    max-width: 80%;
    backdrop-filter: blur(10px);
    opacity: 0;
    transition: opacity 0.3s ease;
    z-index: 15;
    text-align: center;
    font-size: 16px;
    border: 1px solid rgba(255,255,255,0.2);
  }

  .shy-chat-overlay.visible {
    opacity: 1;
  }

  /* Call incoming modal */
  .incoming-call-modal {
    position: fixed;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    background: rgba(0,0,0,0.8);
    z-index: 4000;
    display: none;
    align-items: center;
    justify-content: center;
    backdrop-filter: blur(10px);
  }

  .incoming-call-modal.active {
    display: flex;
  }

  .call-modal-content {
    background: var(--card-bg);
    border-radius: 24px;
    padding: 40px;
    text-align: center;
    max-width: 400px;
    width: 90%;
    box-shadow: 0 20px 60px rgba(0,0,0,0.3);
    animation: modalSlideIn 0.3s ease;
  }

  .caller-avatar {
    width: 100px;
    height: 100px;
    border-radius: 50%;
    margin: 0 auto 20px;
    border: 4px solid var(--primary);
    object-fit: cover;
  }

  .caller-info h3 {
    font-size: 24px;
    margin-bottom: 10px;
    color: var(--text-color);
  }

  .call-type {
    color: var(--secondary-text);
    margin-bottom: 30px;
    font-size: 16px;
  }

  .call-actions {
    display: flex;
    gap: 20px;
    justify-content: center;
  }

  .accept-call-btn {
    background: var(--success);
    color: white;
    border: none;
    width: 60px;
    height: 60px;
    border-radius: 50%;
    cursor: pointer;
    font-size: 24px;
    transition: all 0.2s ease;
  }

  .decline-call-btn {
    background: var(--error);
    color: white;
    border: none;
    width: 60px;
    height: 60px;
    border-radius: 50%;
    cursor: pointer;
    font-size: 24px;
    transition: all 0.2s ease;
  }

  .accept-call-btn:hover,
  .decline-call-btn:hover {
    transform: scale(1.1);
  }

  /* Voice message recording */
  .voice-message-container {
    display: none;
    position: absolute;
    bottom: 80px;
    left: 50%;
    transform: translateX(-50%);
    background: var(--card-bg);
    border-radius: 20px;
    padding: 20px;
    box-shadow: 0 10px 40px rgba(0,0,0,0.2);
    z-index: 100;
    min-width: 300px;
    text-align: center;
    border: 1px solid var(--border-color);
  }

  .voice-message-container.recording {
    display: block;
  }

  .recording-indicator {
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 15px;
    margin-bottom: 15px;
  }

  .recording-dot {
    width: 12px;
    height: 12px;
    background: var(--error);
    border-radius: 50%;
    animation: pulse 1.5s infinite;
  }

  @keyframes pulse {
    0%, 100% { opacity: 1; }
    50% { opacity: 0.5; }
  }

  .recording-timer {
    font-size: 16px;
    font-weight: 600;
    color: var(--text-color);
  }

  .recording-controls {
    display: flex;
    gap: 15px;
    justify-content: center;
  }

  .stop-recording-btn {
    background: var(--error);
    color: white;
    border: none;
    width: 50px;
    height: 50px;
    border-radius: 50%;
    cursor: pointer;
    font-size: 18px;
    transition: all 0.2s ease;
  }

  .cancel-recording-btn {
    background: var(--secondary-text);
    color: white;
    border: none;
    width: 50px;
    height: 50px;
    border-radius: 50%;
    cursor: pointer;
    font-size: 18px;
    transition: all 0.2s ease;
  }

  .stop-recording-btn:hover,
  .cancel-recording-btn:hover {
    transform: scale(1.1);
  }

  /* Audio message styling */
  .audio-message {
    display: flex;
    align-items: center;
    gap: 10px;
    padding: 10px 15px;
    background: var(--bg-color);
    border-radius: 20px;
    max-width: 250px;
  }

  .audio-message.sent {
    background: var(--primary);
    color: white;
  }

  .audio-controls {
    display: flex;
    align-items: center;
    gap: 10px;
  }

  .play-pause-btn {
    background: none;
    border: none;
    color: inherit;
    cursor: pointer;
    font-size: 18px;
    width: 30px;
    height: 30px;
    display: flex;
    align-items: center;
    justify-content: center;
    border-radius: 50%;
    transition: all 0.2s ease;
  }

  .play-pause-btn:hover {
    background: rgba(255,255,255,0.1);
  }

  .audio-progress {
    flex: 1;
    height: 4px;
    background: rgba(255,255,255,0.3);
    border-radius: 2px;
    overflow: hidden;
  }

  .audio-progress-bar {
    height: 100%;
    background: white;
    width: 0%;
    transition: width 0.1s linear;
  }

  .audio-duration {
    font-size: 12px;
    opacity: 0.8;
    min-width: 40px;
  }

  /* Call shy chat input */
  .call-chat-input {
    position: absolute;
    bottom: 120px;
    left: 50%;
    transform: translateX(-50%);
    display: none;
    gap: 10px;
    z-index: 20;
  }

  .call-active .call-chat-input {
    display: flex;
  }

  .call-chat-input input {
    padding: 12px 20px;
    border-radius: 25px;
    border: none;
    background: rgba(255,255,255,0.1);
    color: white;
    backdrop-filter: blur(10px);
    width: 300px;
    font-size: 14px;
    outline: none;
  }

  .call-chat-input input::placeholder {
    color: rgba(255,255,255,0.7);
  }

  .call-chat-send-btn {
    background: var(--primary);
    color: white;
    border: none;
    width: 45px;
    height: 45px;
    border-radius: 50%;
    cursor: pointer;
    font-size: 16px;
    transition: all 0.2s ease;
  }

  .call-chat-send-btn:hover {
    background: var(--primary-dark);
    transform: scale(1.1);
  }

  /* Responsive call interface */
  @media (max-width: 768px) {
    .local-video-container {
      width: 80px;
      height: 120px;
      top: 10px;
      right: 10px;
    }

    .call-btn {
      width: 50px;
      height: 50px;
      font-size: 18px;
    }

    .call-info {
      top: 15px;
      left: 15px;
      padding: 10px 15px;
    }

    .caller-name {
      font-size: 18px;
    }

    .call-chat-input {
      width: 90%;
      bottom: 100px;
    }

    .call-chat-input input {
      width: 100%;
    }

    .remote-video-wrapper {
      width: 100%;
      height: 100%;
      border-radius: 0;
    }
  }

  /* [Rest of your existing CSS remains the same] */
</style>
</head>
<body>
<div class="sidebar-overlay" id="sidebarOverlay" onclick="toggleSidebar()"></div>
<div class="app-container">
  <!-- Sidebar (unchanged) -->
  <div class="sidebar" id="mainSidebar">
    <div class="sidebar-header">
      <h2>MEET</h2>
      <button onclick="toggleSidebar()" style="background:none; border:none; color:white; font-size:24px; padding:8px; border-radius:50%; transition:all 0.2s ease;" onmouseover="this.style.background='rgba(255,255,255,0.2)'" onmouseout="this.style.background='none'"><i class="fas fa-times"></i></button>
    </div>
    <ul class="sidebar-menu">
      <li><a href="feed.html"><i class="fas fa-home"></i> <span>Feed</span></a></li>
      <li><a href="profile.html"><i class="fas fa-user"></i> <span>Profile</span></a></li>
      <li><a href="chat.html" class="active"><i class="fas fa-comment"></i> <span>Chat</span></a></li>
      <li><a href="conference.html"><i class="fas fa-video"></i> <span>Conference</span></a></li>
      <li><a href="meetrader.html"><i class="fas fa-store"></i> <span>Meetrader</span></a></li>
    </ul>
  </div>

  <!-- Main Content -->
  <div class="main-content">
    <!-- Navbar (unchanged) -->
    <div class="navbar">
      <div class="navbar-left">
        <button class="hamburger-btn" onclick="toggleSidebar()"><i class="fas fa-bars"></i></button>
        <h2 style="font-weight:600; font-size:22px;">Chat</h2>
      </div>
      <div class="navbar-right">
        <img src="https://via.placeholder.com/40" id="navUserImg" class="nav-user-img" alt="Me">
        <span id="navUserName" class="nav-user-name"></span>
        <button class="btn" id="nightToggleBtn"><i class="fas fa-moon"></i></button>
        <button class="btn" id="logoutBtn"><i class="fas fa-sign-out-alt"></i></button>
      </div>
    </div>

    <!-- Chat Container -->
    <div class="chat-container">
      <!-- Conversations sidebar (unchanged) -->
      <div class="conversations-sidebar" id="conversationsSidebar">
        <div class="chat-header">
          <h3>Messages</h3>
          <button class="new-chat-btn" onclick="openUserSearchOverlay()"><i class="fas fa-plus"></i></button>
        </div>
        <div class="chat-search">
          <input type="text" placeholder="Search chats..." id="chatSearch">
        </div>
        <div class="conversations-list" id="conversationsList">
          <!-- Conversations will be loaded here -->
        </div>
      </div>

      <!-- Chat Area -->
      <div class="chat-area" id="chatArea">
        <!-- Empty chat state (unchanged) -->
        <div id="emptyChat" class="empty-chat">
          <i class="far fa-comments"></i>
          <h3>Select a conversation</h3>
          <p>Choose a contact to start chatting and stay connected with your network</p>
        </div>

        <!-- Chat header with call buttons -->
        <div class="chat-area-header" id="chatHeader" style="display: none;">
          <button class="chat-action-btn" id="backButton" style="color:var(--text-color); margin-right:5px;"><i class="fas fa-arrow-left"></i></button>
          <img src="" id="currentChatAvatar" class="conversation-avatar">
          <div class="chat-user-info">
            <div class="chat-user-name" id="chatUserName">User</div>
            <div class="chat-user-status">Last seen recently</div>
          </div>
          <div class="chat-actions">
            <button class="chat-action-btn" onclick="openSettingsModal()" title="Chat Settings"><i class="fas fa-sliders-h"></i></button>
            <button class="chat-action-btn" onclick="startVoiceCall()" title="Voice Call"><i class="fas fa-phone-alt"></i></button>
            <button class="chat-action-btn" onclick="startVideoCall()" title="Video Call"><i class="fas fa-video"></i></button>
            <button class="chat-action-btn" onclick="openWallpaperModal()" title="Wallpaper"><i class="fas fa-image"></i></button>
            <button class="chat-action-btn" id="voiceMessageBtn" title="Voice Message"><i class="fas fa-microphone"></i></button>
          </div>
        </div>

        <!-- Messages container (unchanged) -->
        <div class="messages-container" id="messagesContainer" style="display: none;"></div>

        <!-- Typing indicator (unchanged) -->
        <div class="typing-indicator" id="typingIndicator">
          <span id="typingUserName">User</span> is typing <span>.</span><span>.</span><span>.</span>
        </div>

        <!-- Message input container with voice message button -->
        <div class="message-input-container" id="messageInputContainer" style="display: none;">
          <!-- Reply preview (unchanged) -->
          <div class="reply-preview-bar" id="replyPreview">
            <div class="reply-preview-content">
              <span class="reply-name" id="replyName">Replying to User</span>
              <span class="reply-text" id="replyText">Message text...</span>
            </div>
            <button onclick="cancelReply()" style="background:none;border:none;cursor:pointer;font-size:20px;color:var(--secondary-text);padding:5px;border-radius:50%;transition:all 0.2s ease;" onmouseover="this.style.background='rgba(239,68,68,0.1)';this.style.color='var(--error)'" onmouseout="this.style.background='none';this.style.color='var(--secondary-text)'">&times;</button>
          </div>
          
          <!-- Writing assist (unchanged) -->
          <div class="writing-assist-bar" id="assistBar">
            <button class="assist-chip" onclick="applyWritingAssist('fix')"><i class="fas fa-spell-check"></i> Fix Grammar</button>
            <button class="assist-chip" onclick="applyWritingAssist('formal')"><i class="fas fa-user-tie"></i> Make Formal</button>
            <button class="assist-chip" onclick="applyWritingAssist('expand')"><i class="fas fa-expand-alt"></i> Expand Text</button>
          </div>

          <div class="message-input-wrapper">
            <div class="message-input-actions">
              <button class="input-action magic-btn" onclick="toggleAssistBar()" title="Writing Assistant"><i class="fas fa-magic"></i></button>
              <button class="input-action" onclick="toggleEmojiPicker()" title="Emoji"><i class="far fa-smile"></i></button>
              <input type="file" id="imageInputHidden" accept="image/*" style="display:none" onchange="uploadToCloudinary(this.files[0], 'image')">
              <input type="file" id="videoInputHidden" accept="video/*" style="display:none" onchange="uploadToCloudinary(this.files[0], 'video')">
              <button class="input-action" onclick="document.getElementById('imageInputHidden').click()" title="Send Image"><i class="fas fa-image"></i></button>
              <button class="input-action" onclick="document.getElementById('videoInputHidden').click()" title="Send Video"><i class="fas fa-video"></i></button>
              <button class="input-action" onclick="toggleVoiceMessage()" title="Voice Message" id="voiceMsgToggleBtn"><i class="fas fa-microphone"></i></button>
            </div>
            <textarea class="message-input" id="messageInput" placeholder="Type a message..." rows="1" spellcheck="true"></textarea>
            <button class="send-button" id="sendButton" title="Send Message"><i class="fas fa-paper-plane"></i></button>
          </div>
          
          <!-- Emoji picker (unchanged) -->
          <div class="emoji-picker" id="emojiPicker">
            <div class="emoji-header" id="emojiNav"></div>
            <div class="emoji-content" id="emojiContent"></div>
          </div>
        </div>

        <!-- Voice message recording UI -->
        <div class="voice-message-container" id="voiceMessageContainer">
          <div class="recording-indicator">
            <div class="recording-dot"></div>
            <div class="recording-timer" id="recordingTimer">00:00</div>
          </div>
          <div class="recording-controls">
            <button class="cancel-recording-btn" onclick="cancelVoiceRecording()">
              <i class="fas fa-times"></i>
            </button>
            <button class="stop-recording-btn" onclick="stopVoiceRecording()">
              <i class="fas fa-stop"></i>
            </button>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>

<!-- WebRTC Call Interface -->
<div class="call-interface" id="callInterface">
  <div class="video-container">
    <div class="local-video-container">
      <video id="localVideo" class="local-video" autoplay muted playsinline></video>
    </div>
    
    <div class="remote-video-container">
      <div class="remote-video-wrapper">
        <video id="remoteVideo" class="video-element" autoplay playsinline></video>
        <!-- Shy chat overlay -->
        <div class="shy-chat-overlay" id="shyChatOverlay"></div>
      </div>
    </div>

    <!-- Call info -->
    <div class="call-info">
      <div class="caller-name" id="callUserName"></div>
      <div class="call-status" id="callStatus">Connecting...</div>
    </div>

    <!-- Call controls -->
    <div class="call-controls">
      <button class="call-btn mute-btn" id="muteBtn" title="Mute/Unmute">
        <i class="fas fa-microphone"></i>
      </button>
      <button class="call-btn video-toggle-btn" id="videoToggleBtn" title="Toggle Video">
        <i class="fas fa-video"></i>
      </button>
      <button class="call-btn end-call-btn" id="endCallBtn" title="End Call">
        <i class="fas fa-phone"></i>
      </button>
    </div>

    <!-- Shy chat input during call -->
    <div class="call-chat-input">
      <input type="text" id="callChatInput" placeholder="Type a message to appear on screen...">
      <button class="call-chat-send-btn" id="callChatSendBtn">
        <i class="fas fa-paper-plane"></i>
      </button>
    </div>
  </div>
</div>

<!-- Incoming Call Modal -->
<div class="incoming-call-modal" id="incomingCallModal">
  <div class="call-modal-content">
    <img src="" class="caller-avatar" id="callerAvatar" alt="Caller">
    <div class="caller-info">
      <h3 id="incomingCallerName">John Doe</h3>
      <div class="call-type" id="incomingCallType">Video Call</div>
    </div>
    <div class="call-actions">
      <button class="decline-call-btn" onclick="declineIncomingCall()">
        <i class="fas fa-phone-slash"></i>
      </button>
      <button class="accept-call-btn" onclick="acceptIncomingCall()">
        <i class="fas fa-phone"></i>
      </button>
    </div>
  </div>
</div>

<!-- All existing modals remain unchanged -->
<!-- Conversation Context Menu -->
<div class="conversation-options-menu" id="conversationOptionsMenu">
  <div class="msg-option-item" onclick="deleteConversation()" style="color:var(--error);"><i class="fas fa-trash-alt"></i> Delete Conversation</div>
</div>

<!-- Settings Modal -->
<div class="settings-modal" id="settingsModal">
  <!-- Content unchanged -->
</div>

<!-- User Search Modal -->
<div class="user-search-overlay" id="userSearchOverlay">
  <!-- Content unchanged -->
</div>

<!-- Wallpaper Modal -->
<div class="wallpaper-modal" id="wallpaperModal">
  <!-- Content unchanged -->
</div>

<!-- Wallpaper Preview Modal -->
<div class="wallpaper-preview-overlay" id="wpPreviewOverlay">
  <!-- Content unchanged -->
</div>

<script type="module">
  import { initializeApp } from "https://www.gstatic.com/firebasejs/10.14.0/firebase-app.js";
  import { getFirestore, collection, addDoc, updateDoc, doc, getDoc, getDocs, onSnapshot, serverTimestamp, query, orderBy, where, setDoc, limit, deleteDoc } from "https://www.gstatic.com/firebasejs/10.14.0/firebase-firestore.js";
  import { getAuth, onAuthStateChanged, signOut } from "https://www.gstatic.com/firebasejs/10.14.0/firebase-auth.js";

  const firebaseConfig = {
    apiKey: "AIzaSyDtqM_pMGIYkUgy0OWGsQbfS9MtYQhrgZM",
    authDomain: "meet-6e159.firebaseapp.com",
    projectId: "meet-6e159",
    storageBucket: "meet-6e159.firebasestorage.app",
    messagingSenderId: "252353608421",
    appId: "1:252353608421:web:6706056048e9a8f12db20c"
  };

  const app = initializeApp(firebaseConfig);
  const db = getFirestore(app);
  const auth = getAuth(app);

  // Global state variables
  let currentUser = null;
  let currentChatId = null;
  let currentChatUser = null;
  let currentChatUserName = '';
  let currentChatUserAvatar = '';
  let unsubscribeMessages = null;
  let unsubscribeConversations = null;
  
  // WebRTC variables
  let peerConnection = null;
  let localStream = null;
  let remoteStream = null;
  let dataChannel = null;
  let isInitiator = false;
  let isCallActive = false;
  let callType = null; // 'video' or 'voice'
  let incomingCallId = null;
  
  // Voice message variables
  let mediaRecorder = null;
  let audioChunks = [];
  let recordingTimer = null;
  let recordingStartTime = null;
  
  // DOM elements for WebRTC
  const callInterface = document.getElementById('callInterface');
  const localVideo = document.getElementById('localVideo');
  const remoteVideo = document.getElementById('remoteVideo');
  const muteBtn = document.getElementById('muteBtn');
  const videoToggleBtn = document.getElementById('videoToggleBtn');
  const endCallBtn = document.getElementById('endCallBtn');
  const callUserName = document.getElementById('callUserName');
  const callStatus = document.getElementById('callStatus');
  const shyChatOverlay = document.getElementById('shyChatOverlay');
  const callChatInput = document.getElementById('callChatInput');
  const callChatSendBtn = document.getElementById('callChatSendBtn');
  const incomingCallModal = document.getElementById('incomingCallModal');
  const callerAvatar = document.getElementById('callerAvatar');
  const incomingCallerName = document.getElementById('incomingCallerName');
  const incomingCallType = document.getElementById('incomingCallType');
  
  // Voice message elements
  const voiceMessageContainer = document.getElementById('voiceMessageContainer');
  const recordingTimerEl = document.getElementById('recordingTimer');
  const voiceMsgToggleBtn = document.getElementById('voiceMsgToggleBtn');
  
  // WebRTC Configuration
  const configuration = {
    iceServers: [
      { urls: 'stun:stun.l.google.com:19302' },
      { urls: 'stun:stun1.l.google.com:19302' },
      { urls: 'stun:stun2.l.google.com:19302' }
    ]
  };

  // === WEBRTC FUNCTIONS ===

  // Initialize WebRTC
  async function initWebRTC() {
    try {
      // Request media permissions based on call type
      const constraints = {
        audio: true,
        video: callType === 'video' ? {
          width: { ideal: 1280 },
          height: { ideal: 720 },
          frameRate: { ideal: 30 }
        } : false
      };

      localStream = await navigator.mediaDevices.getUserMedia(constraints);
      
      if (callType === 'video') {
        localVideo.srcObject = localStream;
      }
      
      return true;
    } catch (error) {
      console.error('Error accessing media devices:', error);
      showError('Unable to access camera/microphone. Please check permissions.');
      return false;
    }
  }

  // Create peer connection
  function createPeerConnection() {
    peerConnection = new RTCPeerConnection(configuration);

    // Add local tracks
    localStream.getTracks().forEach(track => {
      peerConnection.addTrack(track, localStream);
    });

    // Handle remote stream
    peerConnection.ontrack = (event) => {
      remoteStream = event.streams[0];
      remoteVideo.srcObject = remoteStream;
      updateCallStatus('Connected');
    };

    // Handle ICE candidates
    peerConnection.onicecandidate = (event) => {
      if (event.candidate) {
        sendSignalingMessage({
          type: 'ice-candidate',
          candidate: event.candidate
        });
      }
    };

    // Handle connection state
    peerConnection.onconnectionstatechange = () => {
      console.log('Connection state:', peerConnection.connectionState);
      if (peerConnection.connectionState === 'connected') {
        updateCallStatus('Connected');
      } else if (peerConnection.connectionState === 'disconnected' || 
                 peerConnection.connectionState === 'failed') {
        endCall();
      }
    };

    // Create data channel for shy chat
    if (isInitiator) {
      dataChannel = peerConnection.createDataChannel('shy-chat');
      setupDataChannel();
    } else {
      peerConnection.ondatachannel = (event) => {
        dataChannel = event.channel;
        setupDataChannel();
      };
    }
  }

  // Setup data channel
  function setupDataChannel() {
    dataChannel.onopen = () => {
      console.log('Data channel opened');
      callChatInput.disabled = false;
      callChatSendBtn.disabled = false;
    };

    dataChannel.onmessage = (event) => {
      const message = event.data;
      displayShyChatMessage(message);
    };
  }

  // Start a call (initiator)
  async function startCall(type) {
    if (!currentChatId || !currentChatUser) {
      showError('Please select a conversation first');
      return;
    }

    callType = type;
    isInitiator = true;
    
    const mediaGranted = await initWebRTC();
    if (!mediaGranted) return;

    createPeerConnection();

    // Create and send offer
    try {
      const offer = await peerConnection.createOffer();
      await peerConnection.setLocalDescription(offer);

      // Send offer via signaling
      await sendSignalingMessage({
        type: 'offer',
        sdp: offer,
        callType: callType,
        callerId: currentUser.uid,
        callerName: await getUserDisplayName(currentUser.uid)
      });

      showCallInterface();
      updateCallStatus('Calling...');
      
    } catch (error) {
      console.error('Error creating offer:', error);
      showError('Failed to start call');
      cleanupMedia();
    }
  }

  // Show call interface
  function showCallInterface() {
    document.body.classList.add('call-active');
    callUserName.textContent = currentChatUserName;
    updateCallStatus('Connecting...');
    
    // Update UI based on call type
    if (callType === 'voice') {
      document.querySelector('.remote-video-wrapper').style.display = 'none';
      document.querySelector('.local-video-container').style.display = 'none';
    } else {
      document.querySelector('.remote-video-wrapper').style.display = 'block';
      document.querySelector('.local-video-container').style.display = 'block';
    }
  }

  // Handle incoming call
  function handleIncomingCall(signalingData) {
    incomingCallId = signalingData.callerId;
    
    // Show incoming call modal
    incomingCallerName.textContent = signalingData.callerName || 'Unknown';
    incomingCallType.textContent = signalingData.callType === 'video' ? 'Video Call' : 'Voice Call';
    callerAvatar.src = currentChatUserAvatar;
    
    incomingCallModal.classList.add('active');
    
    // Auto decline after 30 seconds
    setTimeout(() => {
      if (incomingCallModal.classList.contains('active')) {
        declineIncomingCall();
      }
    }, 30000);
  }

  // Accept incoming call
  async function acceptIncomingCall() {
    callType = incomingCallType.textContent.includes('Video') ? 'video' : 'voice';
    isInitiator = false;
    
    const mediaGranted = await initWebRTC();
    if (!mediaGranted) {
      declineIncomingCall();
      return;
    }

    createPeerConnection();
    
    // Set remote description
    await peerConnection.setRemoteDescription(new RTCSessionDescription({
      type: 'offer',
      sdp: incomingCallSignalingData.sdp
    }));

    // Create and send answer
    const answer = await peerConnection.createAnswer();
    await peerConnection.setLocalDescription(answer);

    await sendSignalingMessage({
      type: 'answer',
      sdp: answer
    });

    incomingCallModal.classList.remove('active');
    showCallInterface();
    updateCallStatus('Connected');
  }

  // Decline incoming call
  function declineIncomingCall() {
    if (incomingCallId) {
      sendSignalingMessage({
        type: 'reject',
        to: incomingCallId
      });
    }
    
    incomingCallModal.classList.remove('active');
    incomingCallId = null;
    incomingCallSignalingData = null;
  }

  // End call
  function endCall() {
    if (peerConnection) {
      peerConnection.close();
      peerConnection = null;
    }
    
    if (localStream) {
      localStream.getTracks().forEach(track => track.stop());
      localStream = null;
    }
    
    if (remoteStream) {
      remoteStream.getTracks().forEach(track => track.stop());
      remoteStream = null;
    }
    
    dataChannel = null;
    isCallActive = false;
    
    document.body.classList.remove('call-active');
    
    // Send call end signal
    if (currentChatUser) {
      sendSignalingMessage({
        type: 'end-call'
      });
    }
  }

  // Toggle mute
  function toggleMute() {
    if (localStream) {
      const audioTrack = localStream.getAudioTracks()[0];
      if (audioTrack) {
        audioTrack.enabled = !audioTrack.enabled;
        muteBtn.classList.toggle('active');
        muteBtn.innerHTML = audioTrack.enabled ? 
          '<i class="fas fa-microphone"></i>' : 
          '<i class="fas fa-microphone-slash"></i>';
      }
    }
  }

  // Toggle video
  function toggleVideo() {
    if (localStream) {
      const videoTrack = localStream.getVideoTracks()[0];
      if (videoTrack) {
        videoTrack.enabled = !videoTrack.enabled;
        videoToggleBtn.classList.toggle('active');
        videoToggleBtn.innerHTML = videoTrack.enabled ? 
          '<i class="fas fa-video"></i>' : 
          '<i class="fas fa-video-slash"></i>';
      }
    }
  }

  // Display shy chat message
  function displayShyChatMessage(message) {
    shyChatOverlay.textContent = message;
    shyChatOverlay.classList.add('visible');
    
    setTimeout(() => {
      shyChatOverlay.classList.remove('visible');
    }, 5000);
  }

  // Send shy chat message
  function sendShyChatMessage() {
    const message = callChatInput.value.trim();
    if (message && dataChannel && dataChannel.readyState === 'open') {
      dataChannel.send(message);
      displayShyChatMessage(`You: ${message}`);
      callChatInput.value = '';
    }
  }

  // Update call status
  function updateCallStatus(status) {
    callStatus.textContent = status;
  }

  // === VOICE MESSAGE FUNCTIONS ===

  // Start voice message recording
  async function startVoiceRecording() {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRecorder = new MediaRecorder(stream);
      audioChunks = [];
      
      mediaRecorder.ondataavailable = (event) => {
        audioChunks.push(event.data);
      };
      
      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
        await sendVoiceMessage(audioBlob);
        
        // Stop all tracks
        stream.getTracks().forEach(track => track.stop());
      };
      
      mediaRecorder.start();
      voiceMessageContainer.classList.add('recording');
      
      // Start timer
      recordingStartTime = Date.now();
      recordingTimer = setInterval(updateRecordingTimer, 1000);
      updateRecordingTimer();
      
    } catch (error) {
      console.error('Error accessing microphone:', error);
      showError('Unable to access microphone for recording');
    }
  }

  // Stop voice recording
  function stopVoiceRecording() {
    if (mediaRecorder && mediaRecorder.state === 'recording') {
      mediaRecorder.stop();
      clearInterval(recordingTimer);
      voiceMessageContainer.classList.remove('recording');
    }
  }

  // Cancel voice recording
  function cancelVoiceRecording() {
    if (mediaRecorder && mediaRecorder.state === 'recording') {
      mediaRecorder.stop();
      clearInterval(recordingTimer);
      voiceMessageContainer.classList.remove('recording');
      
      // Stop tracks
      mediaRecorder.stream.getTracks().forEach(track => track.stop());
    }
  }

  // Update recording timer
  function updateRecordingTimer() {
    if (recordingStartTime) {
      const elapsed = Math.floor((Date.now() - recordingStartTime) / 1000);
      const minutes = Math.floor(elapsed / 60).toString().padStart(2, '0');
      const seconds = (elapsed % 60).toString().padStart(2, '0');
      recordingTimerEl.textContent = `${minutes}:${seconds}`;
      
      // Auto-stop after 2 minutes
      if (elapsed >= 120) {
        stopVoiceRecording();
      }
    }
  }

  // Send voice message
  async function sendVoiceMessage(audioBlob) {
    if (!currentChatId) return;
    
    // Convert blob to base64 for Firestore
    const reader = new FileReader();
    reader.readAsDataURL(audioBlob);
    
    reader.onloadend = async () => {
      const base64Audio = reader.result;
      
      try {
        await addDoc(collection(db, "conversations", currentChatId, "messages"), {
          type: 'audio',
          audioData: base64Audio,
          duration: Math.floor((Date.now() - recordingStartTime) / 1000),
          senderId: currentUser.uid,
          timestamp: serverTimestamp()
        });
        
        // Update conversation
        await updateDoc(doc(db, "conversations", currentChatId), {
          lastMessage: 'Voice message',
          updatedAt: serverTimestamp()
        });
        
      } catch (error) {
        console.error('Error sending voice message:', error);
        showError('Failed to send voice message');
      }
    };
  }

  // Toggle voice message recording
  function toggleVoiceMessage() {
    if (voiceMessageContainer.classList.contains('recording')) {
      stopVoiceRecording();
    } else {
      startVoiceRecording();
    }
  }

  // Render audio message
  function renderAudioMessageHTML(msg, isMe, id) {
    const div = document.createElement('div');
    div.className = `audio-message ${isMe ? 'sent' : 'received'}`;
    div.id = id;
    
    const audio = new Audio();
    audio.src = msg.audioData;
    
    const playPauseBtn = document.createElement('button');
    playPauseBtn.className = 'play-pause-btn';
    playPauseBtn.innerHTML = '<i class="fas fa-play"></i>';
    
    const progressBar = document.createElement('div');
    progressBar.className = 'audio-progress';
    const progressFill = document.createElement('div');
    progressFill.className = 'audio-progress-bar';
    progressBar.appendChild(progressFill);
    
    const durationSpan = document.createElement('span');
    durationSpan.className = 'audio-duration';
    durationSpan.textContent = formatDuration(msg.duration || 0);
    
    // Get audio duration
    audio.addEventListener('loadedmetadata', () => {
      durationSpan.textContent = formatDuration(audio.duration);
    });
    
    playPauseBtn.onclick = () => {
      if (audio.paused) {
        audio.play();
        playPauseBtn.innerHTML = '<i class="fas fa-pause"></i>';
      } else {
        audio.pause();
        playPauseBtn.innerHTML = '<i class="fas fa-play"></i>';
      }
    };
    
    audio.addEventListener('timeupdate', () => {
      const progress = (audio.currentTime / audio.duration) * 100;
      progressFill.style.width = `${progress}%`;
      
      if (audio.currentTime === audio.duration) {
        playPauseBtn.innerHTML = '<i class="fas fa-play"></i>';
      }
    });
    
    audio.addEventListener('pause', () => {
      playPauseBtn.innerHTML = '<i class="fas fa-play"></i>';
    });
    
    const controlsDiv = document.createElement('div');
    controlsDiv.className = 'audio-controls';
    controlsDiv.appendChild(playPauseBtn);
    controlsDiv.appendChild(progressBar);
    controlsDiv.appendChild(durationSpan);
    
    div.appendChild(controlsDiv);
    
    return div;
  }

  // Format duration
  function formatDuration(seconds) {
    const mins = Math.floor(seconds / 60);
    const secs = Math.floor(seconds % 60);
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  }

  // === SIGNALING FUNCTIONS ===

  let incomingCallSignalingData = null;

  // Send signaling message
  async function sendSignalingMessage(message) {
    if (!currentChatId || !currentChatUser) return;
    
    try {
      // Use Firestore for signaling
      const signalingRef = collection(db, "signaling", currentChatId, "messages");
      await addDoc(signalingRef, {
        ...message,
        from: currentUser.uid,
        to: currentChatUser,
        timestamp: serverTimestamp()
      });
    } catch (error) {
      console.error('Error sending signaling message:', error);
    }
  }

  // Listen for signaling messages
  function setupSignalingListener() {
    if (!currentChatId || !currentChatUser) return;
    
    const signalingQuery = query(
      collection(db, "signaling", currentChatId, "messages"),
      where("to", "==", currentUser.uid),
      orderBy("timestamp", "desc"),
      limit(10)
    );
    
    return onSnapshot(signalingQuery, (snapshot) => {
      snapshot.docChanges().forEach((change) => {
        if (change.type === "added") {
          const data = change.doc.data();
          handleSignalingMessage(data);
        }
      });
    });
  }

  // Handle signaling messages
  function handleSignalingMessage(message) {
    switch (message.type) {
      case 'offer':
        if (!isCallActive) {
          incomingCallSignalingData = message;
          handleIncomingCall(message);
        }
        break;
        
      case 'answer':
        if (peerConnection && peerConnection.signalingState === 'have-local-offer') {
          peerConnection.setRemoteDescription(new RTCSessionDescription({
            type: 'answer',
            sdp: message.sdp
          }));
          updateCallStatus('Connected');
        }
        break;
        
      case 'ice-candidate':
        if (peerConnection) {
          peerConnection.addIceCandidate(new RTCIceCandidate(message.candidate));
        }
        break;
        
      case 'reject':
        if (isInitiator) {
          showError('Call was declined');
          endCall();
        }
        break;
        
      case 'end-call':
        endCall();
        break;
    }
  }

  // === INTEGRATION WITH EXISTING CHAT ===

  // Modify existing functions to include WebRTC
  window.startVideoCall = () => {
    startCall('video');
  };

  window.startVoiceCall = () => {
    startCall('voice');
  };

  // Clean up media
  function cleanupMedia() {
    if (localStream) {
      localStream.getTracks().forEach(track => track.stop());
      localStream = null;
    }
  }

  // Update message rendering to handle audio messages
  function renderMessageHTML(msg, isMe, id) {
    // Check if it's an audio message
    if (msg.type === 'audio') {
      return renderAudioMessageHTML(msg, isMe, id);
    }
    
    // Existing message rendering code...
    // [Keep your existing renderMessageHTML function, but add audio type check at beginning]
  }

  // === EVENT LISTENERS ===

  // WebRTC event listeners
  endCallBtn.addEventListener('click', endCall);
  muteBtn.addEventListener('click', toggleMute);
  videoToggleBtn.addEventListener('click', toggleVideo);
  callChatSendBtn.addEventListener('click', sendShyChatMessage);
  callChatInput.addEventListener('keypress', (e) => {
    if (e.key === 'Enter') {
      sendShyChatMessage();
    }
  });

  // Voice message event listeners
  voiceMsgToggleBtn.addEventListener('click', toggleVoiceMessage);
  document.getElementById('voiceMessageBtn').addEventListener('click', toggleVoiceMessage);

  // Update existing onAuthStateChanged to setup signaling
  onAuthStateChanged(auth, async user => {
    if (!user) {
      window.location.href = 'login.html';
    } else {
      currentUser = user;
      
      // Existing user setup code...
      
      // Setup signaling listener when user is authenticated
      if (currentChatId) {
        setupSignalingListener();
      }
    }
  });

  // Update openChat function to setup signaling
  async function openChat(chatId, otherUserId, name, avatar) {
    // Existing code...
    
    // Setup signaling listener for this chat
    setupSignalingListener();
  }

  // Cleanup on page unload
  window.addEventListener('beforeunload', () => {
    endCall();
    cleanupMedia();
  });

  // [Keep all your existing chat functions - they remain unchanged]
  // Only add the WebRTC functions above and integrate them as shown

</script>
</body>
  </html>
